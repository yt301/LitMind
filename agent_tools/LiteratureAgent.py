from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.agents import initialize_agent, Tool
from langchain import hub
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from agent_tools.InputModels import TranslateInput, SummaryInput
from agent_tools.TranslationTools import general_translate, academic_translate
from agent_tools.SearchTools import search_tool, literature_search
from agent_tools.SummaryTools import summarize_literature
from langchain.tools import StructuredTool
from agent_tools.Prompts import PROMPT_AGENT_SYSTEM
from dotenv import load_dotenv

load_dotenv()


# ä¸agentäº¤äº’çš„æ–¹æ³•ï¼ˆå¼‚æ­¥ï¼‰
# response = await self.agent_executor.ainvoke({"input": user_input})
# ä¸agentäº¤äº’çš„æ–¹æ³•ï¼ˆåŒæ­¥ï¼‰
# response = self.agent_executor.invoke({"input": user_input})


class LiteratureAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        self.tools = [
            StructuredTool.from_function(
                func=lambda text, source_language, translated_language, style: general_translate(
                    self.llm, text, source_language, translated_language, style
                ),
                name="GeneralTranslator",
                description="é€‚åˆæ—¥å¸¸å¯¹è¯ã€éæ­£å¼æ–‡æœ¬çš„æµç•…ç¿»è¯‘ï¼ˆgeneralé£æ ¼ç¿»è¯‘ï¼‰",
                args_schema=TranslateInput,  # å®šä¹‰å‚æ•°çš„ç»“æ„åŒ–è¾“å…¥
                return_direct=False  # ç»•è¿‡Agentçš„ç»“æœå¤„ç†ï¼Œç›´æ¥è¿”å›å·¥å…·è°ƒç”¨ç»“æœ
            ),

            StructuredTool.from_function(
                func=lambda text, source_language, translated_language, style: academic_translate(
                    self.llm, text, source_language, translated_language, style
                ),
                name="AcademicTranslator",
                description="é€‚åˆè®ºæ–‡ã€æŠ€æœ¯æ–‡æ¡£ç­‰ä¸¥è°¨åœºæ™¯çš„å­¦æœ¯ç¿»è¯‘ï¼ˆacademicé£æ ¼ç¿»è¯‘ï¼‰",
                args_schema=TranslateInput,  # å®šä¹‰å‚æ•°çš„ç»“æ„åŒ–è¾“å…¥
                return_direct=False  # True:ç»•è¿‡Agentçš„ç»“æœå¤„ç†ï¼Œç›´æ¥è¿”å›å·¥å…·è°ƒç”¨ç»“æœ
            ),

            StructuredTool.from_function(
                func=lambda text, language, detail_level: summarize_literature(
                    self.llm, text, language, detail_level
                ),
                name="LiteratureSummarizer",
                description="å­¦æœ¯æ–‡çŒ®æ€»ç»“å·¥å…·ï¼Œèƒ½å¤Ÿä»æ–‡çŒ®å†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯å¹¶ç”Ÿæˆç»“æ„åŒ–æ€»ç»“",
                args_schema=SummaryInput,
                return_direct=False
            ),
            literature_search,

        ]
        # self.agent_prompt = hub.pull("hwchase17/openai-tools-agent")
        # åŠ è½½ Agent çš„ Promptï¼ˆLangChain Hub æˆ–è‡ªå®šä¹‰ï¼‰
        self.agent_prompt = ChatPromptTemplate.from_messages([
            ("system", PROMPT_AGENT_SYSTEM),  # ç³»ç»ŸæŒ‡ä»¤ï¼ˆå›ºå®šï¼‰
            MessagesPlaceholder("chat_history", optional=True),  # å¯¹è¯å†å²ï¼ˆåŠ¨æ€ï¼‰
            ("human", "{input}"),  # å½“å‰ç”¨æˆ·è¾“å…¥ï¼ˆåŠ¨æ€ï¼‰
            MessagesPlaceholder("agent_scratchpad")  # Agentæ‰§è¡Œè¿‡ç¨‹è®°å½•ï¼ˆè‡ªåŠ¨å¡«å……ï¼‰
        ])

        # åˆ›å»º Agent
        self.agent = create_openai_tools_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.agent_prompt
        )
        self.agent_executor = AgentExecutor(agent=self.agent,
                                            tools=self.tools,
                                            verbose=True,  # verbose=True å¯ç”¨äºè°ƒè¯•ï¼Œè¾“å‡ºè¯¦ç»†æ—¥å¿—
                                            # max_iterations=1,  # é™åˆ¶åªä½¿ç”¨ä¸€æ¬¡å·¥å…·å‡½æ•°
                                            return_intermediate_steps=True  # å¯ç”¨ä¸­é—´æ­¥éª¤æ•è·ï¼Œèƒ½ç›´æ¥è·å–å·¥å…·è°ƒç”¨ç»“æœ
                                            )

    async def translate(self, text: str, source_language: str, translated_language: str, style: str) -> str:
        """æ–‡çŒ®ç¿»è¯‘å…¥å£æ–¹æ³•ï¼Œæ ¹æ®styleé€‰æ‹©ä¸åŒçš„ç¿»è¯‘å·¥å…·"""
        response = await self.agent_executor.ainvoke({
            "input": {
                "text": text,
                "source_language": source_language,
                "translated_language": translated_language,
                "style": style  # ç¡®ä¿styleå‚æ•°æ˜¾å¼ä¼ é€’
            }
        })

        # æå–æœ€åä¸€æ¬¡å·¥å…·è°ƒç”¨çš„åŸå§‹ç»“æœ
        if response.get("intermediate_steps"):
            last_action, last_result = response["intermediate_steps"][-1]
            if last_action.tool == "GeneralTranslator" or last_action.tool == "AcademicTranslator":
                return last_result  # ç›´æ¥è¿”å›ç¿»è¯‘ç»“æœ
        # å¦‚æœæ²¡æœ‰ä¸­é—´æ­¥éª¤æˆ–æœªè°ƒç”¨å·¥å…·ï¼Œå›é€€åˆ°é»˜è®¤è¾“å‡º
        return response["output"]

    async def summary(self, text: str, language: str, detail_level: str) -> str:
        """æ–‡çŒ®æ€»ç»“å·¥å…·å…¥å£æ–¹æ³•"""
        response = await self.agent_executor.ainvoke({
            "input": {
                "text": text,
                "language": language,
                "detail_level": detail_level  # ç¡®ä¿detail_levelå‚æ•°æ˜¾å¼ä¼ é€’
            },
            "return_intermediate_steps": True  # å¯ç”¨ä¸­é—´æ­¥éª¤æ•è·ï¼Œèƒ½ç›´æ¥è·å–å·¥å…·è°ƒç”¨ç»“æœ
        })

        # æå–æœ€åä¸€æ¬¡å·¥å…·è°ƒç”¨çš„åŸå§‹ç»“æœ
        if response.get("intermediate_steps"):
            last_action, last_result = response["intermediate_steps"][-1]
            if last_action.tool == "LiteratureSummarizer":
                return last_result  # ç›´æ¥è¿”å›æ–‡çŒ®æ€»ç»“ç»“æœ
        # å¦‚æœæ²¡æœ‰ä¸­é—´æ­¥éª¤æˆ–æœªè°ƒç”¨å·¥å…·ï¼Œå›é€€åˆ°é»˜è®¤è¾“å‡º
        return response["output"]

    async def talk(self, user_input: str) -> str:
        """ä¸Agentè¿›è¡Œå¯¹è¯"""
        response = await self.agent_executor.ainvoke({
            "input": user_input,
        })
        # print("Response:", response)  # æ‰“å°å®Œæ•´çš„å“åº”å†…å®¹

        literature_summary=""
        # å¦‚æœæ˜¯æ–‡çŒ®æ€»ç»“å·¥å…·ï¼Œè®°å½•å·¥å…·è¿”å›ç»“æœ
        if response.get("intermediate_steps"):
            for action,result in response["intermediate_steps"]:
                if action.tool== "LiteratureSummarizer":
                    literature_summary += str(result)
        # print("æ–‡çŒ®æ€»ç»“ç»“æœï¼š", literature_summary)
        final_response = literature_summary+"\n\n" + response["output"]  # å°†æ€»ç»“ç»“æœå’Œæœ€ç»ˆè¾“å‡ºåˆå¹¶
        # print("æœ€ç»ˆè¾“å‡ºï¼š",final_response)
        return final_response

    async def gain_all_tools_result(self, user_input: str) -> str:
        """ä¸Agentè¿›è¡Œå¯¹è¯ï¼Œå¹¶è¿”å›æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœ"""
        response = await self.agent_executor.ainvoke({
            "input": user_input
        })
        # print(response)
        # æ”¶é›†æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœ
        tool_results = []
        if response.get("intermediate_steps"):
            for action, observation in response["intermediate_steps"]:
                tool_name = action.tool
                tool_input = action.tool_input
                tool_output = observation  # è¿™æ˜¯å·¥å…·çš„ç›´æ¥è¿”å›ç»“æœ
                tool_results.append(
                    f"ğŸ”§ å·¥å…·è°ƒç”¨: {tool_name}\n"
                    f"ğŸ“Œ è¾“å…¥å‚æ•°: {tool_input}\n"
                    f"ğŸ“¢ è¿”å›ç»“æœ: {tool_output}\n"
                    "----------------------------------------\n"
                )

        # æ„å»ºæœ€ç»ˆè¾“å‡º
        final_response = ""
        if tool_results:
            final_response += "=== å·¥å…·è°ƒç”¨è®°å½• ===\n" + "\n".join(tool_results) + "\n\n"
        final_response += "=== Agent æœ€ç»ˆè¾“å‡º ===\n" + response["output"]
        # print(final_response)
        return final_response
